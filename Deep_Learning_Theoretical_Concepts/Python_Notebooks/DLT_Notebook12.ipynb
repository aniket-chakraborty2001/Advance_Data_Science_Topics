{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"5dEgRpy3952M","executionInfo":{"status":"ok","timestamp":1708578365378,"user_tz":-330,"elapsed":15,"user":{"displayName":"S N S Acharya","userId":"14786945180387920086"}}},"outputs":[],"source":["## Load libraries\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import matplotlib.cm as cm\n","plt.style.use('dark_background')\n","%matplotlib inline"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"G9W_1_v_6yq7","executionInfo":{"status":"ok","timestamp":1708578365379,"user_tz":-330,"elapsed":13,"user":{"displayName":"S N S Acharya","userId":"14786945180387920086"}}},"outputs":[],"source":["np.set_printoptions(precision=2)"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"4T7eUtw7Mh0z","executionInfo":{"status":"ok","timestamp":1708578368957,"user_tz":-330,"elapsed":3591,"user":{"displayName":"S N S Acharya","userId":"14786945180387920086"}}},"outputs":[],"source":["import tensorflow as tf"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"Q1e2N5S8MlCU","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1708578368958,"user_tz":-330,"elapsed":12,"user":{"displayName":"S N S Acharya","userId":"14786945180387920086"}},"outputId":"6a297b66-cf40-4c87-dc2a-bcc983288ba7"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'2.15.0'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":4}],"source":["tf.__version__"]},{"cell_type":"markdown","source":["---\n","\n","Convolution example:\n","\n","![](https://onedrive.live.com/embed?resid=37720F927B6DDC34%21104168&authkey=%21ADjt5cD8McHWdv8&width=660)\n","\n","---"],"metadata":{"id":"5m3AS9OWck2U"}},{"cell_type":"code","source":["# Define input volume\n","input_volume = np.array([[\n","    [0, 0, 0, 0, 0, 0, 0],\n","    [0, 1, 0, 1, 2, 1, 0],\n","    [0, 0, 2, 2, 0, 1, 0],\n","    [0, 1, 1, 0, 2, 1, 0],\n","    [0, 0, 2, 1, 1, 0, 0],\n","    [0, 2, 1, 1, 2, 0, 0],\n","    [0, 0, 0, 0, 0, 0, 0]\n","]], dtype=np.float32)\n","\n","# Add 3rd dimension for volume\n","input_volume = np.expand_dims(input_volume, axis=-1)\n","\n","# Define filter (a.k.a. weights)\n","W = np.array([[\n","    [ 0, 0, -1],\n","    [ 0, 1, 0 ],\n","    [-2, 0, 2 ]\n","]], dtype=np.float32)\n","\n","# Define bias\n","b = np.array([1], dtype=np.float32)"],"metadata":{"id":"sJ1YobXTcqWW","executionInfo":{"status":"ok","timestamp":1708578568318,"user_tz":-330,"elapsed":4,"user":{"displayName":"S N S Acharya","userId":"14786945180387920086"}}},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":["---\n","\n","Build a model with only one convolutional layer initialized by $\\mathbf{W}$ and $b.$\n","\n","---"],"metadata":{"id":"v3O38h7tdwDM"}},{"cell_type":"code","source":["model = tf.keras.models.Sequential([\n","    tf.keras.layers.Conv2D(\n","        filters = 1,\n","        kernel_size = [3, 3],\n","        kernel_initializer = tf.constant_initializer(W),\n","        bias_initializer = tf.constant_initializer(b)\n","    )]\n",")"],"metadata":{"id":"gaum_IIJdvSM","executionInfo":{"status":"ok","timestamp":1708578635472,"user_tz":-330,"elapsed":517,"user":{"displayName":"S N S Acharya","userId":"14786945180387920086"}}},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":["---\n","\n","Feed the input volume into the model and print the output.\n","\n","---"],"metadata":{"id":"oyKC37FFep6P"}},{"cell_type":"code","source":["output = model(input_volume)\n","print(output.shape)\n","print(tf.squeeze(output))"],"metadata":{"id":"zru0AG0uex3d","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1708578665604,"user_tz":-330,"elapsed":735,"user":{"displayName":"S N S Acharya","userId":"14786945180387920086"}},"outputId":"7bbe1d07-d986-4c02-db16-d943e013669e"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["(1, 5, 5, 1)\n","tf.Tensor(\n","[[ 6.  5. -2.  1.  2.]\n"," [ 3.  0.  3.  2. -2.]\n"," [ 4.  2. -1.  0.  0.]\n"," [ 2.  1.  2. -1. -3.]\n"," [ 1.  1.  1.  3.  1.]], shape=(5, 5), dtype=float32)\n"]}]},{"cell_type":"markdown","source":["---\n","\n","Add a max-pooling layer.\n","\n","---"],"metadata":{"id":"zpVWyC_ihSJI"}},{"cell_type":"code","source":["max_pool_2d = tf.keras.layers.MaxPooling2D(pool_size=(2, 2),\n","                                           strides = (1, 1),\n","                                           padding='valid')"],"metadata":{"id":"-nvihlgQhWDb","executionInfo":{"status":"ok","timestamp":1708578813247,"user_tz":-330,"elapsed":503,"user":{"displayName":"S N S Acharya","userId":"14786945180387920086"}}},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":["---\n","\n","Apply max-pooling to the output of the convolution layer\n","\n","---"],"metadata":{"id":"AojoXJwRhgQe"}},{"cell_type":"code","source":["tf.squeeze(max_pool_2d(output))"],"metadata":{"id":"MTTjzA89hmD6","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1708578816541,"user_tz":-330,"elapsed":534,"user":{"displayName":"S N S Acharya","userId":"14786945180387920086"}},"outputId":"650cdb1d-5f3d-4710-a4af-419796c8140a"},"execution_count":14,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tf.Tensor: shape=(4, 4), dtype=float32, numpy=\n","array([[6., 5., 3., 2.],\n","       [4., 3., 3., 2.],\n","       [4., 2., 2., 0.],\n","       [2., 2., 3., 3.]], dtype=float32)>"]},"metadata":{},"execution_count":14}]},{"cell_type":"markdown","source":["---\n","\n","MNISTLoader class to read data from the MNIST dataset.\n","\n","Note that in TensorFlow, a typical representation of an image data set is a four-dimensional tensor of [number of images, width, height, number of color channels]. In the DataLoader class above, self.train_data and self.test_data were loaded with 60,000 and 10,000 handwritten digit images of size 28x28, respectively. Since we are reading a grayscale image here with only one color channel (a regular RGB color image has 3 color channels), we use the np.expand_dims() function to manually add one dimensional channels at the last dimension for the image data.\n","\n","---"],"metadata":{"id":"vTQ7MPwXjenu"}},{"cell_type":"code","source":["class MNISTLoader():\n","    def __init__(self):\n","        mnist = tf.keras.datasets.mnist\n","        (self.train_data, self.train_label), (self.test_data, self.test_label) = mnist.load_data()\n","        self.train_data = np.expand_dims(self.train_data.astype(np.float32) / 255.0, axis=-1)      # [60000, 28, 28, 1]\n","        self.test_data = np.expand_dims(self.test_data.astype(np.float32) / 255.0, axis=-1)        # [10000, 28, 28, 1]\n","        self.train_label = self.train_label.astype(np.int32)    # [60000]\n","        self.test_label = self.test_label.astype(np.int32)      # [10000]\n","        self.num_train_data, self.num_test_data = self.train_data.shape[0], self.test_data.shape[0]\n","\n","    def get_batch(self, batch_size):\n","        index = np.random.randint(0, self.num_train_data, batch_size)\n","        return self.train_data[index, :], self.train_label[index]"],"metadata":{"id":"VkMEXSMsjx4C","executionInfo":{"status":"ok","timestamp":1708580515758,"user_tz":-330,"elapsed":513,"user":{"displayName":"S N S Acharya","userId":"14786945180387920086"}}},"execution_count":22,"outputs":[]},{"cell_type":"markdown","source":["---\n","\n","Define a fully-connected neural network model.\n","\n","The model accepts a vector (e.g. here a flattened 1Ã—784 handwritten digit image) as input and outputs a 10-dimensional vector representing the probability that this image belongs to 0 to 9 respectively.\n","\n","---"],"metadata":{"id":"-RKts24vj8eV"}},{"cell_type":"code","source":["class FCN(tf.keras.Model):\n","    def __init__(self):\n","        super().__init__()\n","        self.flatten = tf.keras.layers.Flatten()\n","        self.dense1 = tf.keras.layers.Dense(units=100, activation=tf.nn.relu)\n","        self.dense2 = tf.keras.layers.Dense(units=10)\n","\n","    def call(self, inputs):         # [batch_size, 28, 28, 1]\n","        x = self.flatten(inputs)    # [batch_size, 784]\n","        x = self.dense1(x)          # [batch_size, 100]\n","        x = self.dense2(x)          # [batch_size, 10]\n","        output = tf.nn.softmax(x)\n","        return output"],"metadata":{"id":"GEMtU2SgkeDR","executionInfo":{"status":"ok","timestamp":1708580961010,"user_tz":-330,"elapsed":508,"user":{"displayName":"S N S Acharya","userId":"14786945180387920086"}}},"execution_count":23,"outputs":[]},{"cell_type":"markdown","source":["---\n","\n","Define hyperparameters of the model used in training process.\n","\n","---"],"metadata":{"id":"1W2kD8ZVk7D_"}},{"cell_type":"code","source":["num_epochs = 5\n","batch_size = 1000\n","learning_rate = 0.001"],"metadata":{"id":"6Ghyamkkk_Jt","executionInfo":{"status":"ok","timestamp":1708582138852,"user_tz":-330,"elapsed":513,"user":{"displayName":"S N S Acharya","userId":"14786945180387920086"}}},"execution_count":38,"outputs":[]},{"cell_type":"markdown","source":["---\n","\n","Instantiate the model and data reading classes, and instantiate an optimizer in tf.keras.optimizer (the Adam optimizer is used here).\n","\n","---"],"metadata":{"id":"EStVRqbYlBXK"}},{"cell_type":"code","source":["model = CNN()\n","data_loader = MNISTLoader()\n","optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)"],"metadata":{"id":"4FunRowBlJ6n","executionInfo":{"status":"ok","timestamp":1708582107830,"user_tz":-330,"elapsed":1292,"user":{"displayName":"S N S Acharya","userId":"14786945180387920086"}}},"execution_count":36,"outputs":[]},{"cell_type":"markdown","source":["---\n","\n","Model training.\n","\n","1. A random batch of training data is taken from the\n","DataLoader.\n","2. Feed the data into the model, and obtain the predicted value from the model.\n","3. Calculate the loss function (loss) by comparing the model predicted value with the true value. Here we use the sparse categorical cross-entropy function in tf.keras.losses as a loss function.\n","4. Calculate the gradient of the loss function on the model variables.\n","5. The gradients are passed into the optimizer, and use the apply_gradients method to update the model variables so that the loss value is minimized.\n","\n","---"],"metadata":{"id":"fLestKV_lR8S"}},{"cell_type":"code","source":["num_batches = int(data_loader.num_train_data // batch_size * num_epochs)\n","for batch_index in range(num_batches):\n","  X, y = data_loader.get_batch(batch_size)\n","  with tf.GradientTape() as tape:\n","    y_pred = model(X)\n","    loss = tf.keras.losses.sparse_categorical_crossentropy(y_true=y, y_pred=y_pred)\n","    loss = tf.reduce_mean(loss)\n","    print(\"batch %d: loss %f\" % (batch_index, loss.numpy()))\n","  grads = tape.gradient(loss, model.variables)\n","  optimizer.apply_gradients(grads_and_vars=zip(grads, model.variables))"],"metadata":{"id":"Gq3DacAMlzKS","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"error","timestamp":1708582262864,"user_tz":-330,"elapsed":117974,"user":{"displayName":"S N S Acharya","userId":"14786945180387920086"}},"outputId":"4c4bcfb6-198e-4c0b-9f06-f621c4b9a81c"},"execution_count":39,"outputs":[{"output_type":"stream","name":"stdout","text":["batch 0: loss 0.290286\n","batch 1: loss 0.265546\n","batch 2: loss 0.251465\n","batch 3: loss 0.278521\n","batch 4: loss 0.277983\n","batch 5: loss 0.206814\n","batch 6: loss 0.231549\n","batch 7: loss 0.242734\n","batch 8: loss 0.198607\n","batch 9: loss 0.230701\n","batch 10: loss 0.181315\n","batch 11: loss 0.184486\n","batch 12: loss 0.175068\n","batch 13: loss 0.228959\n","batch 14: loss 0.176043\n","batch 15: loss 0.201831\n","batch 16: loss 0.204633\n","batch 17: loss 0.157745\n","batch 18: loss 0.156266\n","batch 19: loss 0.122394\n","batch 20: loss 0.152576\n","batch 21: loss 0.129373\n","batch 22: loss 0.140789\n","batch 23: loss 0.161130\n","batch 24: loss 0.149253\n","batch 25: loss 0.158900\n","batch 26: loss 0.145901\n","batch 27: loss 0.108223\n","batch 28: loss 0.111316\n","batch 29: loss 0.109740\n","batch 30: loss 0.116526\n","batch 31: loss 0.136346\n","batch 32: loss 0.152749\n","batch 33: loss 0.120175\n","batch 34: loss 0.090257\n","batch 35: loss 0.101567\n","batch 36: loss 0.155162\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-39-6cb712303cbd>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_mean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"batch %d: loss %f\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m   \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m   \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads_and_vars\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/backprop.py\u001b[0m in \u001b[0;36mgradient\u001b[0;34m(self, target, sources, output_gradients, unconnected_gradients)\u001b[0m\n\u001b[1;32m   1064\u001b[0m                           for x in output_gradients]\n\u001b[1;32m   1065\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1066\u001b[0;31m     flat_grad = imperative_grad.imperative_grad(\n\u001b[0m\u001b[1;32m   1067\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1068\u001b[0m         \u001b[0mflat_targets\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/imperative_grad.py\u001b[0m in \u001b[0;36mimperative_grad\u001b[0;34m(tape, target, sources, output_gradients, sources_raw, unconnected_gradients)\u001b[0m\n\u001b[1;32m     65\u001b[0m         \"Unknown value for unconnected_gradients: %r\" % unconnected_gradients)\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m   return pywrap_tfe.TFE_Py_TapeGradient(\n\u001b[0m\u001b[1;32m     68\u001b[0m       \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tape\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/backprop.py\u001b[0m in \u001b[0;36m_gradient_function\u001b[0;34m(op_name, attr_tuple, num_inputs, inputs, outputs, out_grads, skip_input_indices, forward_pass_name_scope)\u001b[0m\n\u001b[1;32m    146\u001b[0m       \u001b[0mgradient_name_scope\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mforward_pass_name_scope\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"/\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradient_name_scope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 148\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmock_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mout_grads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    149\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmock_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mout_grads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/ops/nn_grad.py\u001b[0m in \u001b[0;36m_Conv2DGrad\u001b[0;34m(op, grad)\u001b[0m\n\u001b[1;32m    582\u001b[0m   \u001b[0;31m# in Eager mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m   return [\n\u001b[0;32m--> 584\u001b[0;31m       gen_nn_ops.conv2d_backprop_input(\n\u001b[0m\u001b[1;32m    585\u001b[0m           \u001b[0mshape_0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    586\u001b[0m           \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/ops/gen_nn_ops.py\u001b[0m in \u001b[0;36mconv2d_backprop_input\u001b[0;34m(input_sizes, filter, out_backprop, strides, padding, use_cudnn_on_gpu, explicit_paddings, data_format, dilations, name)\u001b[0m\n\u001b[1;32m   1857\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mtld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_eager\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1858\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1859\u001b[0;31m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[0m\u001b[1;32m   1860\u001b[0m         \u001b[0m_ctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Conv2DBackpropInput\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_sizes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_backprop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1861\u001b[0m         \u001b[0;34m\"strides\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"use_cudnn_on_gpu\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_cudnn_on_gpu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"padding\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"markdown","source":["---\n","\n","Output the accuracy of the trained model on the test set.\n","\n","---"],"metadata":{"id":"iW2ciUydmauf"}},{"cell_type":"code","source":["sparse_categorical_accuracy = tf.keras.metrics.SparseCategoricalAccuracy()\n","num_batches = int(data_loader.num_test_data // batch_size)\n","for batch_index in range(num_batches):\n","  start_index, end_index = batch_index * batch_size, (batch_index + 1) * batch_size\n","  y_pred = model.predict(data_loader.test_data[start_index: end_index])\n","  sparse_categorical_accuracy.update_state(y_true=data_loader.test_label[start_index: end_index], y_pred=y_pred)\n","print(\"test accuracy: %f\" % sparse_categorical_accuracy.result())"],"metadata":{"id":"yf_1m03mmfLg","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1708581853186,"user_tz":-330,"elapsed":5900,"user":{"displayName":"S N S Acharya","userId":"14786945180387920086"}},"outputId":"7cae9c3b-20e9-4f31-9b28-d70cf989393c"},"execution_count":34,"outputs":[{"output_type":"stream","name":"stdout","text":["7/7 [==============================] - 0s 4ms/step\n","7/7 [==============================] - 0s 2ms/step\n","7/7 [==============================] - 0s 2ms/step\n","7/7 [==============================] - 0s 3ms/step\n","7/7 [==============================] - 0s 2ms/step\n","7/7 [==============================] - 0s 2ms/step\n","7/7 [==============================] - 0s 2ms/step\n","7/7 [==============================] - 0s 3ms/step\n","7/7 [==============================] - 0s 3ms/step\n","7/7 [==============================] - 0s 2ms/step\n","7/7 [==============================] - 0s 2ms/step\n","7/7 [==============================] - 0s 2ms/step\n","7/7 [==============================] - 0s 3ms/step\n","7/7 [==============================] - 0s 3ms/step\n","7/7 [==============================] - 0s 2ms/step\n","7/7 [==============================] - 0s 2ms/step\n","7/7 [==============================] - 0s 2ms/step\n","7/7 [==============================] - 0s 3ms/step\n","7/7 [==============================] - 0s 4ms/step\n","7/7 [==============================] - 0s 2ms/step\n","7/7 [==============================] - 0s 2ms/step\n","7/7 [==============================] - 0s 2ms/step\n","7/7 [==============================] - 0s 2ms/step\n","7/7 [==============================] - 0s 2ms/step\n","7/7 [==============================] - 0s 2ms/step\n","7/7 [==============================] - 0s 3ms/step\n","7/7 [==============================] - 0s 3ms/step\n","7/7 [==============================] - 0s 2ms/step\n","7/7 [==============================] - 0s 4ms/step\n","7/7 [==============================] - 0s 3ms/step\n","7/7 [==============================] - 0s 2ms/step\n","7/7 [==============================] - 0s 2ms/step\n","7/7 [==============================] - 0s 2ms/step\n","7/7 [==============================] - 0s 2ms/step\n","7/7 [==============================] - 0s 2ms/step\n","7/7 [==============================] - 0s 2ms/step\n","7/7 [==============================] - 0s 3ms/step\n","7/7 [==============================] - 0s 2ms/step\n","7/7 [==============================] - 0s 3ms/step\n","7/7 [==============================] - 0s 3ms/step\n","7/7 [==============================] - 0s 2ms/step\n","7/7 [==============================] - 0s 3ms/step\n","7/7 [==============================] - 0s 2ms/step\n","7/7 [==============================] - 0s 3ms/step\n","7/7 [==============================] - 0s 3ms/step\n","7/7 [==============================] - 0s 2ms/step\n","7/7 [==============================] - 0s 2ms/step\n","7/7 [==============================] - 0s 2ms/step\n","7/7 [==============================] - 0s 2ms/step\n","7/7 [==============================] - 0s 2ms/step\n","test accuracy: 0.965300\n"]}]},{"cell_type":"markdown","source":["---\n","\n","Define CNN Model\n","\n","---"],"metadata":{"id":"K-qnAK3Om4Z5"}},{"cell_type":"code","source":["class CNN(tf.keras.Model):\n","    def __init__(self):\n","        super().__init__()\n","        self.conv1 = tf.keras.layers.Conv2D(\n","            filters=32,\n","            kernel_size=[5, 5],\n","            padding='same',\n","            activation=tf.nn.relu\n","        )\n","        self.pool1 = tf.keras.layers.MaxPool2D(pool_size=[2, 2], strides=2)\n","        self.conv2 = tf.keras.layers.Conv2D(\n","            filters=64,\n","            kernel_size=[5, 5],\n","            padding='same',\n","            activation=tf.nn.relu\n","        )\n","        self.pool2 = tf.keras.layers.MaxPool2D(pool_size=[2, 2], strides=2)\n","        self.flatten = tf.keras.layers.Reshape(target_shape=(7 * 7 * 64,))\n","        self.dense1 = tf.keras.layers.Dense(units=1024, activation=tf.nn.relu)\n","        self.dense2 = tf.keras.layers.Dense(units=10)\n","\n","    def call(self, inputs):\n","        x = self.conv1(inputs)                  # [batch_size, 28, 28, 32]\n","        x = self.pool1(x)                       # [batch_size, 14, 14, 32]\n","        x = self.conv2(x)                       # [batch_size, 14, 14, 64]\n","        x = self.pool2(x)                       # [batch_size, 7, 7, 64]\n","        x = self.flatten(x)                     # [batch_size, 7 * 7 * 64]\n","        x = self.dense1(x)                      # [batch_size, 1024]\n","        x = self.dense2(x)                      # [batch_size, 10]\n","        output = tf.nn.softmax(x)\n","        return output"],"metadata":{"id":"hoQRtDibncws","executionInfo":{"status":"ok","timestamp":1708582089186,"user_tz":-330,"elapsed":511,"user":{"displayName":"S N S Acharya","userId":"14786945180387920086"}}},"execution_count":35,"outputs":[]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"}},"nbformat":4,"nbformat_minor":0}