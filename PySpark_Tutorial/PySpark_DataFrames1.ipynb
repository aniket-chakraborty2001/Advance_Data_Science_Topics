{"cells":[{"cell_type":"markdown","id":"00166693","metadata":{"id":"00166693"},"source":["#### In this Notebook We will go through the following things -\n","- PySpark Dataframe\n","- Reading The Dataset\n","- Checking the Datatypes of the Column(Schema)\n","- Selecting Columns And Indexing\n","- Check Describe option similar to Pandas\n","- Adding Columns\n","- Dropping columns\n","- Renaming Columns"]},{"cell_type":"code","source":["# Connecting Google colab with drive\n","from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AKVhY9e_dNpU","executionInfo":{"status":"ok","timestamp":1731550621705,"user_tz":-330,"elapsed":21599,"user":{"displayName":"Aniket Chakraborty","userId":"02339058060356792309"}},"outputId":"5f8d02c3-06be-41f3-a98e-c712b1a695ce"},"id":"AKVhY9e_dNpU","execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["# Import the pyspark library\n","import pyspark"],"metadata":{"id":"ke4ASHxwcpOs","executionInfo":{"status":"ok","timestamp":1731550445966,"user_tz":-330,"elapsed":931,"user":{"displayName":"Aniket Chakraborty","userId":"02339058060356792309"}}},"id":"ke4ASHxwcpOs","execution_count":1,"outputs":[]},{"cell_type":"code","execution_count":2,"id":"fb37d003","metadata":{"id":"fb37d003","executionInfo":{"status":"ok","timestamp":1731550449373,"user_tz":-330,"elapsed":611,"user":{"displayName":"Aniket Chakraborty","userId":"02339058060356792309"}}},"outputs":[],"source":["# Initializing the SparkSession\n","from pyspark.sql import SparkSession"]},{"cell_type":"code","execution_count":3,"id":"a1d46445","metadata":{"id":"a1d46445","executionInfo":{"status":"ok","timestamp":1731550501830,"user_tz":-330,"elapsed":16953,"user":{"displayName":"Aniket Chakraborty","userId":"02339058060356792309"}}},"outputs":[],"source":["# Build the spark object with 'Dataframe' app name as spark\n","spark = SparkSession.builder.appName('Dataframe').getOrCreate()"]},{"cell_type":"code","execution_count":4,"id":"078fccba","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":219},"id":"078fccba","executionInfo":{"status":"ok","timestamp":1731550512390,"user_tz":-330,"elapsed":2370,"user":{"displayName":"Aniket Chakraborty","userId":"02339058060356792309"}},"outputId":"dcf7ff51-c9ba-4f7c-dacc-9943564b43fd"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["<pyspark.sql.session.SparkSession at 0x7902b1ff4070>"],"text/html":["\n","            <div>\n","                <p><b>SparkSession - in-memory</b></p>\n","                \n","        <div>\n","            <p><b>SparkContext</b></p>\n","\n","            <p><a href=\"http://97c2dec293ab:4040\">Spark UI</a></p>\n","\n","            <dl>\n","              <dt>Version</dt>\n","                <dd><code>v3.5.3</code></dd>\n","              <dt>Master</dt>\n","                <dd><code>local[*]</code></dd>\n","              <dt>AppName</dt>\n","                <dd><code>Dataframe</code></dd>\n","            </dl>\n","        </div>\n","        \n","            </div>\n","        "]},"metadata":{},"execution_count":4}],"source":["# Get details on the spark object just created\n","spark"]},{"cell_type":"code","execution_count":6,"id":"b7b4a628","metadata":{"id":"b7b4a628","executionInfo":{"status":"ok","timestamp":1731551081741,"user_tz":-330,"elapsed":9606,"user":{"displayName":"Aniket Chakraborty","userId":"02339058060356792309"}}},"outputs":[],"source":["# Read the 'PySpark_test1.csv' dataset as df_pyspark with the first row as header\n","df_pyspark = spark.read.option('header','true').csv('/content/drive/MyDrive/Datasets/PySpark_test1.csv', inferSchema = True)\n","\n","# The inferschema = True option makes the schema as it should be\n","# Otherwise, it will give all the column types as string objects"]},{"cell_type":"code","execution_count":7,"id":"79a95903","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"79a95903","executionInfo":{"status":"ok","timestamp":1731551088213,"user_tz":-330,"elapsed":443,"user":{"displayName":"Aniket Chakraborty","userId":"02339058060356792309"}},"outputId":"e8833531-48fe-447f-d30d-ec9f0ba7cf36"},"outputs":[{"output_type":"stream","name":"stdout","text":["root\n"," |-- Name: string (nullable = true)\n"," |-- age: integer (nullable = true)\n"," |-- Experience: integer (nullable = true)\n"," |-- Salary: integer (nullable = true)\n","\n"]}],"source":["### Check the schema\n","df_pyspark.printSchema()"]},{"cell_type":"code","execution_count":8,"id":"8a0d131b","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8a0d131b","executionInfo":{"status":"ok","timestamp":1731551277292,"user_tz":-330,"elapsed":2133,"user":{"displayName":"Aniket Chakraborty","userId":"02339058060356792309"}},"outputId":"ed15530f-6bc0-45c0-c326-3aa8d436a6b9"},"outputs":[{"output_type":"stream","name":"stdout","text":["+---------+---+----------+------+\n","|     Name|age|Experience|Salary|\n","+---------+---+----------+------+\n","|    Krish| 31|        10| 30000|\n","|Sudhanshu| 30|         8| 25000|\n","|    Sunny| 29|         4| 20000|\n","|     Paul| 24|         3| 20000|\n","|   Harsha| 21|         1| 15000|\n","|  Shubham| 23|         2| 18000|\n","+---------+---+----------+------+\n","\n"]}],"source":["# Combining the header and inferschema in a more simple way\n","df_pyspark = spark.read.csv('/content/drive/MyDrive/Datasets/PySpark_test1.csv', header = True, inferSchema = True)\n","df_pyspark.show()"]},{"cell_type":"code","execution_count":9,"id":"47a5a108","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"47a5a108","executionInfo":{"status":"ok","timestamp":1731551311862,"user_tz":-330,"elapsed":420,"user":{"displayName":"Aniket Chakraborty","userId":"02339058060356792309"}},"outputId":"a88b318b-a3de-4042-fe37-46d315a03d04"},"outputs":[{"output_type":"stream","name":"stdout","text":["root\n"," |-- Name: string (nullable = true)\n"," |-- age: integer (nullable = true)\n"," |-- Experience: integer (nullable = true)\n"," |-- Salary: integer (nullable = true)\n","\n"]}],"source":["# Check the schema for the new data frame df_pyspark, created by combining the codes\n","df_pyspark.printSchema() # It works perfectly"]},{"cell_type":"code","execution_count":10,"id":"19da5885","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"19da5885","executionInfo":{"status":"ok","timestamp":1731551385554,"user_tz":-330,"elapsed":426,"user":{"displayName":"Aniket Chakraborty","userId":"02339058060356792309"}},"outputId":"c6ee42e1-94e1-4d36-83d6-36697215e4b0"},"outputs":[{"output_type":"stream","name":"stdout","text":["<class 'pyspark.sql.dataframe.DataFrame'>\n"]}],"source":["# Check the type of df_pyspark data frame\n","print(type(df_pyspark))"]},{"cell_type":"code","execution_count":11,"id":"e4a3c8eb","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"e4a3c8eb","executionInfo":{"status":"ok","timestamp":1731551412954,"user_tz":-330,"elapsed":419,"user":{"displayName":"Aniket Chakraborty","userId":"02339058060356792309"}},"outputId":"63d46253-b246-4a9d-c1df-2536838c3672"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["[Row(Name='Krish', age=31, Experience=10, Salary=30000),\n"," Row(Name='Sudhanshu', age=30, Experience=8, Salary=25000),\n"," Row(Name='Sunny', age=29, Experience=4, Salary=20000)]"]},"metadata":{},"execution_count":11}],"source":["# Check first three records of the df_pyspark dataframe\n","df_pyspark.head(3)"]},{"cell_type":"code","execution_count":13,"id":"5523ae24","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5523ae24","executionInfo":{"status":"ok","timestamp":1731551512174,"user_tz":-330,"elapsed":400,"user":{"displayName":"Aniket Chakraborty","userId":"02339058060356792309"}},"outputId":"0ba6a6e3-bbac-403e-8dad-163c64aad6cb"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["['Name', 'age', 'Experience', 'Salary']"]},"metadata":{},"execution_count":13}],"source":["# Get the column names of the df_pyspark dataframe\n","df_pyspark.columns"]},{"cell_type":"code","execution_count":17,"id":"c513816d","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"c513816d","executionInfo":{"status":"ok","timestamp":1731551895883,"user_tz":-330,"elapsed":832,"user":{"displayName":"Aniket Chakraborty","userId":"02339058060356792309"}},"outputId":"b8d2fa3c-431a-428a-c613-384924c3151e"},"outputs":[{"output_type":"stream","name":"stdout","text":["+---------+----------+\n","|     Name|Experience|\n","+---------+----------+\n","|    Krish|        10|\n","|Sudhanshu|         8|\n","|    Sunny|         4|\n","|     Paul|         3|\n","|   Harsha|         1|\n","|  Shubham|         2|\n","+---------+----------+\n","\n"]}],"source":["# How to access the columns and their entries for the df_pyspark dataframe\n","# This is done by using the select() method and the action show() is performed to get the result\n","# The return type is dataframe\n","\n","# df_pyspark.select('Name').show()\n","# df_pyspark.select('age').show()\n","df_pyspark.select(['Name','Experience']).show() # For more than one column to access, input a list of columns"]},{"cell_type":"code","execution_count":18,"id":"a8bd20e3","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"a8bd20e3","executionInfo":{"status":"ok","timestamp":1731551898131,"user_tz":-330,"elapsed":437,"user":{"displayName":"Aniket Chakraborty","userId":"02339058060356792309"}},"outputId":"bba289c9-82eb-4c72-903c-7e1e32e93371"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["Column<'Name'>"]},"metadata":{},"execution_count":18}],"source":["# Accessing the 'Name' column as pandas\n","df_pyspark['Name'] # It is just a column, so .show() method will not work"]},{"cell_type":"code","execution_count":20,"id":"c3d42722","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"c3d42722","executionInfo":{"status":"ok","timestamp":1731551969230,"user_tz":-330,"elapsed":410,"user":{"displayName":"Aniket Chakraborty","userId":"02339058060356792309"}},"outputId":"1264c8fe-27ff-411f-afa6-6321edb09ae5"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["[('Name', 'string'), ('age', 'int'), ('Experience', 'int'), ('Salary', 'int')]"]},"metadata":{},"execution_count":20}],"source":["# Check the data types that lies inside df_pyspark variable\n","# It is same as the pandas dataframe\n","# It provides the column name and its type in a tuple like object, that are elements of a list\n","df_pyspark.dtypes"]},{"cell_type":"code","execution_count":22,"id":"fa74b18e","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fa74b18e","executionInfo":{"status":"ok","timestamp":1731552266085,"user_tz":-330,"elapsed":850,"user":{"displayName":"Aniket Chakraborty","userId":"02339058060356792309"}},"outputId":"fd0fc7b5-31f5-4775-cff4-a9e6d1379c39"},"outputs":[{"output_type":"stream","name":"stdout","text":["+-------+------+------------------+-----------------+------------------+\n","|summary|  Name|               age|       Experience|            Salary|\n","+-------+------+------------------+-----------------+------------------+\n","|  count|     6|                 6|                6|                 6|\n","|   mean|  NULL|26.333333333333332|4.666666666666667|21333.333333333332|\n","| stddev|  NULL| 4.179314138308661|3.559026084010437| 5354.126134736337|\n","|    min|Harsha|                21|                1|             15000|\n","|    max| Sunny|                31|               10|             30000|\n","+-------+------+------------------+-----------------+------------------+\n","\n"]}],"source":["# Get the summary statistics from the df_pyspark column\n","# We use .describe().show() to obtain the results\n","# Unlike pandas dataframe, the describe() method of pyspark also returns the result for string variables like 'Name'\n","# The code: df_pyspark.describe() will return a dataframe without the result: that shows the column name and type\n","# To resolve this .show() is used\n","df_pyspark.describe().show()"]},{"cell_type":"code","execution_count":23,"id":"6a8d7b54","metadata":{"id":"6a8d7b54","executionInfo":{"status":"ok","timestamp":1731552540813,"user_tz":-330,"elapsed":416,"user":{"displayName":"Aniket Chakraborty","userId":"02339058060356792309"}}},"outputs":[],"source":["# Adding Columns in pyspark data frame df_pyspark\n","# The new column is named as 'Experience2': that captures the experience after 2 years\n","# To create a new column is pyspark dataframes, 'withColumn' function is used that takes two parameters as input\n","# The first parameter is the name of the new column\n","# The second parameter is how the new column is defined\n","df_pyspark = df_pyspark.withColumn('Experience2', df_pyspark['Experience'] + 2)\n","\n","# It is not an inplace operation, you need to assign it into another variable"]},{"cell_type":"code","execution_count":24,"id":"e9ff01ed","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"e9ff01ed","executionInfo":{"status":"ok","timestamp":1731552560361,"user_tz":-330,"elapsed":433,"user":{"displayName":"Aniket Chakraborty","userId":"02339058060356792309"}},"outputId":"201ca44e-67ac-49f4-a665-173ecf485fce"},"outputs":[{"output_type":"stream","name":"stdout","text":["+---------+---+----------+------+-----------+\n","|     Name|age|Experience|Salary|Experience2|\n","+---------+---+----------+------+-----------+\n","|    Krish| 31|        10| 30000|         12|\n","|Sudhanshu| 30|         8| 25000|         10|\n","|    Sunny| 29|         4| 20000|          6|\n","|     Paul| 24|         3| 20000|          5|\n","|   Harsha| 21|         1| 15000|          3|\n","|  Shubham| 23|         2| 18000|          4|\n","+---------+---+----------+------+-----------+\n","\n"]}],"source":["# Get the complete data frame after creating a new column\n","df_pyspark.show()"]},{"cell_type":"code","execution_count":25,"id":"d98641db","metadata":{"id":"d98641db","executionInfo":{"status":"ok","timestamp":1731552781977,"user_tz":-330,"elapsed":421,"user":{"displayName":"Aniket Chakraborty","userId":"02339058060356792309"}}},"outputs":[],"source":["# Drop the columns: specifically drop the column 'Experience2'\n","# The drop() method is used just like pandas data frame\n","# It takes the column names by default: it can take one column name in (), or multiple column names in list format inside ()\n","df_pyspark = df_pyspark.drop('Experience2')\n","\n","# This is also not an inplace operation\n","# Need to assign the result in a variable"]},{"cell_type":"code","execution_count":26,"id":"e0a2723f","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"e0a2723f","executionInfo":{"status":"ok","timestamp":1731552803565,"user_tz":-330,"elapsed":426,"user":{"displayName":"Aniket Chakraborty","userId":"02339058060356792309"}},"outputId":"ea53b3a0-9350-4fa3-8cd2-98b1a7bd4c85"},"outputs":[{"output_type":"stream","name":"stdout","text":["+---------+---+----------+------+\n","|     Name|age|Experience|Salary|\n","+---------+---+----------+------+\n","|    Krish| 31|        10| 30000|\n","|Sudhanshu| 30|         8| 25000|\n","|    Sunny| 29|         4| 20000|\n","|     Paul| 24|         3| 20000|\n","|   Harsha| 21|         1| 15000|\n","|  Shubham| 23|         2| 18000|\n","+---------+---+----------+------+\n","\n"]}],"source":["# Check the data frame after droping the 'Experience2' column\n","df_pyspark.show()"]},{"cell_type":"code","execution_count":27,"id":"5432faa1","metadata":{"id":"5432faa1","executionInfo":{"status":"ok","timestamp":1731553006404,"user_tz":-330,"elapsed":420,"user":{"displayName":"Aniket Chakraborty","userId":"02339058060356792309"}}},"outputs":[],"source":["# Rename the columns: old name is 'Name' and new name is 'New Name'\n","# It uses the withColumnRenamed function\n","# Takes two inputs: the first input the the old name, the second input is the new name\n","df_pyspark = df_pyspark.withColumnRenamed('Name','New Name')\n","\n","# This is also not an inplace operation\n","# Need to assign the result in a variable"]},{"cell_type":"code","execution_count":28,"id":"2e5b7d72","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2e5b7d72","executionInfo":{"status":"ok","timestamp":1731553031000,"user_tz":-330,"elapsed":435,"user":{"displayName":"Aniket Chakraborty","userId":"02339058060356792309"}},"outputId":"66ac83aa-c6b9-4dbe-a125-90835c487a56"},"outputs":[{"output_type":"stream","name":"stdout","text":["+---------+---+----------+------+\n","| New Name|age|Experience|Salary|\n","+---------+---+----------+------+\n","|    Krish| 31|        10| 30000|\n","|Sudhanshu| 30|         8| 25000|\n","|    Sunny| 29|         4| 20000|\n","|     Paul| 24|         3| 20000|\n","|   Harsha| 21|         1| 15000|\n","|  Shubham| 23|         2| 18000|\n","+---------+---+----------+------+\n","\n"]}],"source":["# Check the renamed pyspark data frame\n","df_pyspark.show()"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.10"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}