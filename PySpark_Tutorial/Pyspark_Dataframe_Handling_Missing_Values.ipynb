{"cells":[{"cell_type":"markdown","id":"ded0783b","metadata":{"id":"ded0783b"},"source":["### Pyspark Handling Missing Values\n","- Dropping Columns\n","- Dropping Rows based on null values\n","- Various Parameter In Dropping functionalities\n","- Handling Missing values by Mean, MEdian And Mode"]},{"cell_type":"code","source":["# Connecting google colab with drive\n","from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uRpJMl8Fm7X_","executionInfo":{"status":"ok","timestamp":1731553209637,"user_tz":-330,"elapsed":11266,"user":{"displayName":"Aniket Chakraborty","userId":"02339058060356792309"}},"outputId":"dd1012fb-e9f1-42b4-fee2-95c6b812d2ca"},"id":"uRpJMl8Fm7X_","execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["# Importing pyspark\n","import pyspark"],"metadata":{"id":"5RAPZ0yDnDz2","executionInfo":{"status":"ok","timestamp":1731553215665,"user_tz":-330,"elapsed":937,"user":{"displayName":"Aniket Chakraborty","userId":"02339058060356792309"}}},"id":"5RAPZ0yDnDz2","execution_count":3,"outputs":[]},{"cell_type":"code","execution_count":4,"id":"805e7382","metadata":{"id":"805e7382","executionInfo":{"status":"ok","timestamp":1731553288462,"user_tz":-330,"elapsed":10832,"user":{"displayName":"Aniket Chakraborty","userId":"02339058060356792309"}}},"outputs":[],"source":["# Importing the SparkSession and building the spark context object with 'HandNullVal' app name as spark\n","from pyspark.sql import SparkSession\n","spark = SparkSession.builder.appName('HandNullVal').getOrCreate()"]},{"cell_type":"code","source":["# Check the details of the spark context object\n","spark"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":219},"id":"V9APlmAunk2W","executionInfo":{"status":"ok","timestamp":1731553302710,"user_tz":-330,"elapsed":2129,"user":{"displayName":"Aniket Chakraborty","userId":"02339058060356792309"}},"outputId":"42746f38-8a4b-4ff7-b695-e466110e9ae9"},"id":"V9APlmAunk2W","execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<pyspark.sql.session.SparkSession at 0x7c061763d240>"],"text/html":["\n","            <div>\n","                <p><b>SparkSession - in-memory</b></p>\n","                \n","        <div>\n","            <p><b>SparkContext</b></p>\n","\n","            <p><a href=\"http://1533a5970da3:4040\">Spark UI</a></p>\n","\n","            <dl>\n","              <dt>Version</dt>\n","                <dd><code>v3.5.3</code></dd>\n","              <dt>Master</dt>\n","                <dd><code>local[*]</code></dd>\n","              <dt>AppName</dt>\n","                <dd><code>HandNullVal</code></dd>\n","            </dl>\n","        </div>\n","        \n","            </div>\n","        "]},"metadata":{},"execution_count":5}]},{"cell_type":"code","source":["# Storing the file path for reading the 'PySpark_test2.csv' file\n","file_path = '/content/drive/MyDrive/Datasets/PySpark_test2.csv'"],"metadata":{"id":"WMxjtr6pnrjH","executionInfo":{"status":"ok","timestamp":1731553364241,"user_tz":-330,"elapsed":438,"user":{"displayName":"Aniket Chakraborty","userId":"02339058060356792309"}}},"id":"WMxjtr6pnrjH","execution_count":6,"outputs":[]},{"cell_type":"code","execution_count":15,"id":"e48ebc07","metadata":{"id":"e48ebc07","executionInfo":{"status":"ok","timestamp":1731554483874,"user_tz":-330,"elapsed":818,"user":{"displayName":"Aniket Chakraborty","userId":"02339058060356792309"}}},"outputs":[],"source":["# Read the 'PySpark_test2.csv' file with first row as header and with the inferschema = True option\n","# Name the spark data frame as df_pyspark\n","df_org = spark.read.csv(file_path, header = True, inferSchema = True)"]},{"cell_type":"code","execution_count":16,"id":"53ab7bbc","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"53ab7bbc","executionInfo":{"status":"ok","timestamp":1731554490897,"user_tz":-330,"elapsed":404,"user":{"displayName":"Aniket Chakraborty","userId":"02339058060356792309"}},"outputId":"0e91aecf-62c9-4a8f-e577-2f9212ac161f"},"outputs":[{"output_type":"stream","name":"stdout","text":["root\n"," |-- Name: string (nullable = true)\n"," |-- age: integer (nullable = true)\n"," |-- Experience: integer (nullable = true)\n"," |-- Salary: integer (nullable = true)\n","\n"]}],"source":["# Check the schema of the 'PySpark_test2.csv' file\n","df_org.printSchema()"]},{"cell_type":"code","execution_count":17,"id":"ed677b30","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ed677b30","executionInfo":{"status":"ok","timestamp":1731554496669,"user_tz":-330,"elapsed":397,"user":{"displayName":"Aniket Chakraborty","userId":"02339058060356792309"}},"outputId":"8565c17f-5d8b-4f98-9c1d-42596ecad53e"},"outputs":[{"output_type":"stream","name":"stdout","text":["+---------+----+----------+------+\n","|     Name| age|Experience|Salary|\n","+---------+----+----------+------+\n","|    Krish|  31|        10| 30000|\n","|Sudhanshu|  30|         8| 25000|\n","|    Sunny|  29|         4| 20000|\n","|     Paul|  24|         3| 20000|\n","|   Harsha|  21|         1| 15000|\n","|  Shubham|  23|         2| 18000|\n","|   Mahesh|NULL|      NULL| 40000|\n","|     NULL|  34|        10| 38000|\n","|     NULL|  36|      NULL|  NULL|\n","+---------+----+----------+------+\n","\n"]}],"source":["# Get the df_pyspark data frame\n","df_org.show()"]},{"cell_type":"code","execution_count":18,"id":"523d3c4e","metadata":{"id":"523d3c4e","executionInfo":{"status":"ok","timestamp":1731554515257,"user_tz":-330,"elapsed":433,"user":{"displayName":"Aniket Chakraborty","userId":"02339058060356792309"}}},"outputs":[],"source":["# Drop the columns from df_pyspark: drop the 'Name' column\n","# Remember it is not an inplace operation, need to assign it to a variable\n","df_dropname = df_org.drop('Name')"]},{"cell_type":"code","execution_count":19,"id":"9c041e07","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9c041e07","executionInfo":{"status":"ok","timestamp":1731554522533,"user_tz":-330,"elapsed":407,"user":{"displayName":"Aniket Chakraborty","userId":"02339058060356792309"}},"outputId":"622d0f91-a9a6-4080-ab24-f1ecb5b8e318"},"outputs":[{"output_type":"stream","name":"stdout","text":["+----+----------+------+\n","| age|Experience|Salary|\n","+----+----------+------+\n","|  31|        10| 30000|\n","|  30|         8| 25000|\n","|  29|         4| 20000|\n","|  24|         3| 20000|\n","|  21|         1| 15000|\n","|  23|         2| 18000|\n","|NULL|      NULL| 40000|\n","|  34|        10| 38000|\n","|  36|      NULL|  NULL|\n","+----+----------+------+\n","\n"]}],"source":["# Check the df_pyspark dataframe after dropping the 'Name' column\n","# The .show() function is used\n","df_dropname.show()"]},{"cell_type":"code","execution_count":20,"id":"36845e38","metadata":{"id":"36845e38","executionInfo":{"status":"ok","timestamp":1731554566062,"user_tz":-330,"elapsed":409,"user":{"displayName":"Aniket Chakraborty","userId":"02339058060356792309"}}},"outputs":[],"source":["# Handling missing values: Drop rows having null entries\n","# To do that .na() is used with drop() function\n","# By using the same .na(), we can fill, replace or remove entries\n","# This is not an inplace operation, need to assign the result in a variable\n","df_dropnullrows = df_org.na.drop()"]},{"cell_type":"code","source":["# Check the df_pyspark data frame with reduced number of rows\n","df_dropnullrows.show() # It has no missing values"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cTW21rAGrP2N","executionInfo":{"status":"ok","timestamp":1731554575807,"user_tz":-330,"elapsed":394,"user":{"displayName":"Aniket Chakraborty","userId":"02339058060356792309"}},"outputId":"2985933f-5bb8-45e8-d73d-927fe20bd8c3"},"id":"cTW21rAGrP2N","execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["+---------+---+----------+------+\n","|     Name|age|Experience|Salary|\n","+---------+---+----------+------+\n","|    Krish| 31|        10| 30000|\n","|Sudhanshu| 30|         8| 25000|\n","|    Sunny| 29|         4| 20000|\n","|     Paul| 24|         3| 20000|\n","|   Harsha| 21|         1| 15000|\n","|  Shubham| 23|         2| 18000|\n","+---------+---+----------+------+\n","\n"]}]},{"cell_type":"code","execution_count":22,"id":"156e41cf","metadata":{"id":"156e41cf","executionInfo":{"status":"ok","timestamp":1731554673606,"user_tz":-330,"elapsed":419,"user":{"displayName":"Aniket Chakraborty","userId":"02339058060356792309"}}},"outputs":[],"source":["# Use the how = 'any' parameter for droping the missing values from df_org\n","# If a row contains atleast one missing value, then it will drop the row\n","df_dropany = df_org.na.drop(how = 'any')"]},{"cell_type":"code","source":["# Check the result of the df_dropany dataframe\n","df_dropany.show() # It is same as the result we get when we drop rows having missing values"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rN9LaOhds-0q","executionInfo":{"status":"ok","timestamp":1731554759446,"user_tz":-330,"elapsed":422,"user":{"displayName":"Aniket Chakraborty","userId":"02339058060356792309"}},"outputId":"2e4d09c2-0ed8-4629-906f-f68c330d6591"},"id":"rN9LaOhds-0q","execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":["+---------+---+----------+------+\n","|     Name|age|Experience|Salary|\n","+---------+---+----------+------+\n","|    Krish| 31|        10| 30000|\n","|Sudhanshu| 30|         8| 25000|\n","|    Sunny| 29|         4| 20000|\n","|     Paul| 24|         3| 20000|\n","|   Harsha| 21|         1| 15000|\n","|  Shubham| 23|         2| 18000|\n","+---------+---+----------+------+\n","\n"]}]},{"cell_type":"code","source":["# Use the how = 'all' parameter for droping the missing values from df_org\n","# If a row contains only missing value, then only it will drop the row, for one non null value: it will not drop the row\n","df_dropall = df_org.na.drop(how = 'all')"],"metadata":{"id":"3DNNhzrPtN7d","executionInfo":{"status":"ok","timestamp":1731554824604,"user_tz":-330,"elapsed":409,"user":{"displayName":"Aniket Chakraborty","userId":"02339058060356792309"}}},"id":"3DNNhzrPtN7d","execution_count":25,"outputs":[]},{"cell_type":"code","source":["# Check the result of the df_dropany dataframe\n","df_dropall.show() # It gives the org data frame as no row have all missing value"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"F3PLUcsZtddm","executionInfo":{"status":"ok","timestamp":1731554879923,"user_tz":-330,"elapsed":4,"user":{"displayName":"Aniket Chakraborty","userId":"02339058060356792309"}},"outputId":"1719bff3-50a3-4982-c7a0-e1b3d58d1a55"},"id":"F3PLUcsZtddm","execution_count":27,"outputs":[{"output_type":"stream","name":"stdout","text":["+---------+----+----------+------+\n","|     Name| age|Experience|Salary|\n","+---------+----+----------+------+\n","|    Krish|  31|        10| 30000|\n","|Sudhanshu|  30|         8| 25000|\n","|    Sunny|  29|         4| 20000|\n","|     Paul|  24|         3| 20000|\n","|   Harsha|  21|         1| 15000|\n","|  Shubham|  23|         2| 18000|\n","|   Mahesh|NULL|      NULL| 40000|\n","|     NULL|  34|        10| 38000|\n","|     NULL|  36|      NULL|  NULL|\n","+---------+----+----------+------+\n","\n"]}]},{"cell_type":"code","execution_count":33,"id":"e9af0da0","metadata":{"id":"e9af0da0","executionInfo":{"status":"ok","timestamp":1731555426239,"user_tz":-330,"elapsed":397,"user":{"displayName":"Aniket Chakraborty","userId":"02339058060356792309"}}},"outputs":[],"source":["# Droping rows with specified threshold values\n","# If threshold value is set as 3: means it will drop the rows where atleast 3 non-null values are present\n","# It will drop the rows having name 'Mahesh' and the last column\n","# So, that row will be deleted. Note, we are using the how = 'any' parameter with the threshold value\n","df_dropthresh3 = df_org.na.drop(how = 'any',thresh = 3)"]},{"cell_type":"code","source":["# Check the result of threshold droping with threshold 3\n","df_dropthresh3.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0y70la6_uwob","executionInfo":{"status":"ok","timestamp":1731555430291,"user_tz":-330,"elapsed":415,"user":{"displayName":"Aniket Chakraborty","userId":"02339058060356792309"}},"outputId":"f72768d3-d708-44ab-d8ff-1335d5e21876"},"id":"0y70la6_uwob","execution_count":34,"outputs":[{"output_type":"stream","name":"stdout","text":["+---------+---+----------+------+\n","|     Name|age|Experience|Salary|\n","+---------+---+----------+------+\n","|    Krish| 31|        10| 30000|\n","|Sudhanshu| 30|         8| 25000|\n","|    Sunny| 29|         4| 20000|\n","|     Paul| 24|         3| 20000|\n","|   Harsha| 21|         1| 15000|\n","|  Shubham| 23|         2| 18000|\n","|     NULL| 34|        10| 38000|\n","+---------+---+----------+------+\n","\n"]}]},{"cell_type":"code","execution_count":35,"id":"787fc949","metadata":{"id":"787fc949","executionInfo":{"status":"ok","timestamp":1731555600024,"user_tz":-330,"elapsed":416,"user":{"displayName":"Aniket Chakraborty","userId":"02339058060356792309"}}},"outputs":[],"source":["# Droping columns from df_org with specified subset\n","# This is useful to drop rows from a specific column\n","# Suppose, we want to drop null values from the 'age' column with how is set as any and with no threshold\n","df_dropsubset = df_org.na.drop(how = 'any', subset=['age'])"]},{"cell_type":"code","source":["# Check the result of the df_dropsubset dataframe object\n","df_dropsubset.show() # The row having name as Mahesh is dropped"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4DJZOrFawbYB","executionInfo":{"status":"ok","timestamp":1731555673375,"user_tz":-330,"elapsed":607,"user":{"displayName":"Aniket Chakraborty","userId":"02339058060356792309"}},"outputId":"f0c71fde-ebbd-4487-95ff-ac91bf017892"},"id":"4DJZOrFawbYB","execution_count":37,"outputs":[{"output_type":"stream","name":"stdout","text":["+---------+---+----------+------+\n","|     Name|age|Experience|Salary|\n","+---------+---+----------+------+\n","|    Krish| 31|        10| 30000|\n","|Sudhanshu| 30|         8| 25000|\n","|    Sunny| 29|         4| 20000|\n","|     Paul| 24|         3| 20000|\n","|   Harsha| 21|         1| 15000|\n","|  Shubham| 23|         2| 18000|\n","|     NULL| 34|        10| 38000|\n","|     NULL| 36|      NULL|  NULL|\n","+---------+---+----------+------+\n","\n"]}]},{"cell_type":"code","execution_count":41,"id":"72bad9ba","metadata":{"id":"72bad9ba","executionInfo":{"status":"ok","timestamp":1731556150980,"user_tz":-330,"elapsed":409,"user":{"displayName":"Aniket Chakraborty","userId":"02339058060356792309"}}},"outputs":[],"source":["# Filling the Missing Value\n","# The .na() function provies another function called fill() that fills the missinge values with specified\n","# Suppose we want to fill all the missing values with  the string entry 'Missing'\n","# Store the result in a variable called df_fillmiss\n","df_fillmissname = df_org.na.fill('Missing')"]},{"cell_type":"code","source":["# Check the df_fillmiss data frame that has no missing values\n","df_fillmissname.show() # See as the 'Missing' is a string, it only fills the name column\n","\n","# To fill the age, Experience and Salary column, we need to specify some interger value"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"I2JGRyQMxn6F","executionInfo":{"status":"ok","timestamp":1731556152364,"user_tz":-330,"elapsed":6,"user":{"displayName":"Aniket Chakraborty","userId":"02339058060356792309"}},"outputId":"39d1f765-0eb9-48f7-bb12-12e6f3b29138"},"id":"I2JGRyQMxn6F","execution_count":42,"outputs":[{"output_type":"stream","name":"stdout","text":["+---------+----+----------+------+\n","|     Name| age|Experience|Salary|\n","+---------+----+----------+------+\n","|    Krish|  31|        10| 30000|\n","|Sudhanshu|  30|         8| 25000|\n","|    Sunny|  29|         4| 20000|\n","|     Paul|  24|         3| 20000|\n","|   Harsha|  21|         1| 15000|\n","|  Shubham|  23|         2| 18000|\n","|   Mahesh|NULL|      NULL| 40000|\n","|  Missing|  34|        10| 38000|\n","|  Missing|  36|      NULL|  NULL|\n","+---------+----+----------+------+\n","\n"]}]},{"cell_type":"code","source":["# Fill the interger missing values with an interger say 20\n","# This will fill the age, Experience and Salary columns\n","df_fillmissint = df_fillmissname.na.fill(20)\n","df_fillmissint.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5kEqmscIyag2","executionInfo":{"status":"ok","timestamp":1731556236347,"user_tz":-330,"elapsed":448,"user":{"displayName":"Aniket Chakraborty","userId":"02339058060356792309"}},"outputId":"6ebce5ca-c2b1-4b8c-a463-bdf7ceb266df"},"id":"5kEqmscIyag2","execution_count":43,"outputs":[{"output_type":"stream","name":"stdout","text":["+---------+---+----------+------+\n","|     Name|age|Experience|Salary|\n","+---------+---+----------+------+\n","|    Krish| 31|        10| 30000|\n","|Sudhanshu| 30|         8| 25000|\n","|    Sunny| 29|         4| 20000|\n","|     Paul| 24|         3| 20000|\n","|   Harsha| 21|         1| 15000|\n","|  Shubham| 23|         2| 18000|\n","|   Mahesh| 20|        20| 40000|\n","|  Missing| 34|        10| 38000|\n","|  Missing| 36|        20|    20|\n","+---------+---+----------+------+\n","\n"]}]},{"cell_type":"code","source":["# Using the subset method of fill() function to fill specific entries\n","# Use the 'age' and 'Experience' column for this\n","df_fillage_exp = df_org.na.fill(20, ['age','Experience'])\n","df_fillage_exp.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vJQTA3mb0CI1","executionInfo":{"status":"ok","timestamp":1731556741581,"user_tz":-330,"elapsed":397,"user":{"displayName":"Aniket Chakraborty","userId":"02339058060356792309"}},"outputId":"9c04ebe3-fd5d-424e-947a-da1aadbbbacf"},"id":"vJQTA3mb0CI1","execution_count":46,"outputs":[{"output_type":"stream","name":"stdout","text":["+---------+---+----------+------+\n","|     Name|age|Experience|Salary|\n","+---------+---+----------+------+\n","|    Krish| 31|        10| 30000|\n","|Sudhanshu| 30|         8| 25000|\n","|    Sunny| 29|         4| 20000|\n","|     Paul| 24|         3| 20000|\n","|   Harsha| 21|         1| 15000|\n","|  Shubham| 23|         2| 18000|\n","|   Mahesh| 20|        20| 40000|\n","|     NULL| 34|        10| 38000|\n","|     NULL| 36|        20|  NULL|\n","+---------+---+----------+------+\n","\n"]}]},{"cell_type":"code","execution_count":47,"id":"64e01bb9","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"64e01bb9","executionInfo":{"status":"ok","timestamp":1731556802088,"user_tz":-330,"elapsed":409,"user":{"displayName":"Aniket Chakraborty","userId":"02339058060356792309"}},"outputId":"c3c6396c-a836-471f-934b-45297a8e410b"},"outputs":[{"output_type":"stream","name":"stdout","text":["+---------+----+----------+------+\n","|     Name| age|Experience|Salary|\n","+---------+----+----------+------+\n","|    Krish|  31|        10| 30000|\n","|Sudhanshu|  30|         8| 25000|\n","|    Sunny|  29|         4| 20000|\n","|     Paul|  24|         3| 20000|\n","|   Harsha|  21|         1| 15000|\n","|  Shubham|  23|         2| 18000|\n","|   Mahesh|NULL|      NULL| 40000|\n","|     NULL|  34|        10| 38000|\n","|     NULL|  36|      NULL|  NULL|\n","+---------+----+----------+------+\n","\n"]}],"source":["# Get the original pyspark dataframe\n","df_org.show()"]},{"cell_type":"code","execution_count":48,"id":"b66832fd","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"b66832fd","executionInfo":{"status":"ok","timestamp":1731558096911,"user_tz":-330,"elapsed":429,"user":{"displayName":"Aniket Chakraborty","userId":"02339058060356792309"}},"outputId":"b7f7e1e6-7862-4979-fe58-81219f06535b"},"outputs":[{"output_type":"stream","name":"stdout","text":["root\n"," |-- Name: string (nullable = true)\n"," |-- age: integer (nullable = true)\n"," |-- Experience: integer (nullable = true)\n"," |-- Salary: integer (nullable = true)\n","\n"]}],"source":["# Get the Schema of the df_org data frame\n","df_org.printSchema()"]},{"cell_type":"code","execution_count":49,"id":"e31190f2","metadata":{"id":"e31190f2","executionInfo":{"status":"ok","timestamp":1731558265394,"user_tz":-330,"elapsed":1001,"user":{"displayName":"Aniket Chakraborty","userId":"02339058060356792309"}}},"outputs":[],"source":["# Importing the imputer function\n","# This will help to fill the column missing values with the mean, mdeian or mode of that specific column\n","# Fill the columns 'age', 'Experience' and 'Salary' with their column mdeian\n","from pyspark.ml.feature import Imputer\n","imputer = Imputer(\n","    inputCols=['age', 'Experience', 'Salary'],\n","    outputCols=[\"{}_imputed\".format(c) for c in ['age', 'Experience', 'Salary']]\n","    ).setStrategy(\"median\")"]},{"cell_type":"code","execution_count":51,"id":"d84c4a3d","metadata":{"id":"d84c4a3d","executionInfo":{"status":"ok","timestamp":1731558337681,"user_tz":-330,"elapsed":793,"user":{"displayName":"Aniket Chakraborty","userId":"02339058060356792309"}}},"outputs":[],"source":["# Fit and transform the df_ord to the above defined imputer object to create a data frame with out any missing values\n","df_imputed = imputer.fit(df_org).transform(df_org)"]},{"cell_type":"code","execution_count":52,"id":"8cd38651","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8cd38651","executionInfo":{"status":"ok","timestamp":1731558364828,"user_tz":-330,"elapsed":432,"user":{"displayName":"Aniket Chakraborty","userId":"02339058060356792309"}},"outputId":"40f8ac54-c91b-47f6-b4e9-73e95f3937fd"},"outputs":[{"output_type":"stream","name":"stdout","text":["+---------+----+----------+------+-----------+------------------+--------------+\n","|     Name| age|Experience|Salary|age_imputed|Experience_imputed|Salary_imputed|\n","+---------+----+----------+------+-----------+------------------+--------------+\n","|    Krish|  31|        10| 30000|         31|                10|         30000|\n","|Sudhanshu|  30|         8| 25000|         30|                 8|         25000|\n","|    Sunny|  29|         4| 20000|         29|                 4|         20000|\n","|     Paul|  24|         3| 20000|         24|                 3|         20000|\n","|   Harsha|  21|         1| 15000|         21|                 1|         15000|\n","|  Shubham|  23|         2| 18000|         23|                 2|         18000|\n","|   Mahesh|NULL|      NULL| 40000|         29|                 4|         40000|\n","|     NULL|  34|        10| 38000|         34|                10|         38000|\n","|     NULL|  36|      NULL|  NULL|         36|                 4|         20000|\n","+---------+----+----------+------+-----------+------------------+--------------+\n","\n"]}],"source":["# Check the result of the imputer fit and transform function\n","df_imputed.show()"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.10"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}