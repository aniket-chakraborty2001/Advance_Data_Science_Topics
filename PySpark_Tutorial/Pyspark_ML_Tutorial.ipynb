{"cells":[{"cell_type":"markdown","id":"16da6c54","metadata":{"id":"16da6c54"},"source":["### Examples Of Pyspark ML"]},{"cell_type":"code","source":["# Connecting google colab with google dive\n","from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-oEabmxClH4a","executionInfo":{"status":"ok","timestamp":1731636619795,"user_tz":-330,"elapsed":29076,"user":{"displayName":"Aniket Chakraborty","userId":"02339058060356792309"}},"outputId":"ce75fff3-dbfc-47aa-94b9-353e2b0ea154"},"id":"-oEabmxClH4a","execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["# Get the file path to read the 'PySpark_test1.csv' file\n","file_path = '/content/drive/MyDrive/Datasets/PySpark_test1.csv'"],"metadata":{"id":"W0txLifblS7F"},"id":"W0txLifblS7F","execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":3,"id":"0b9da3ad","metadata":{"id":"0b9da3ad","executionInfo":{"status":"ok","timestamp":1731636737219,"user_tz":-330,"elapsed":10798,"user":{"displayName":"Aniket Chakraborty","userId":"02339058060356792309"}}},"outputs":[],"source":["# Importing the SparkSession and creating the spark context as spark with 'BaseML' app name\n","from pyspark.sql import SparkSession\n","spark = SparkSession.builder.appName('BaseML').getOrCreate()"]},{"cell_type":"code","execution_count":5,"id":"735525da","metadata":{"id":"735525da","executionInfo":{"status":"ok","timestamp":1731636824316,"user_tz":-330,"elapsed":989,"user":{"displayName":"Aniket Chakraborty","userId":"02339058060356792309"}}},"outputs":[],"source":["# Read the 'PySpark_test1.csv' dataset as train_df\n","train_df = spark.read.csv(file_path, header = True, inferSchema = True)"]},{"cell_type":"code","execution_count":6,"id":"d6e038c9","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"d6e038c9","executionInfo":{"status":"ok","timestamp":1731636830898,"user_tz":-330,"elapsed":1061,"user":{"displayName":"Aniket Chakraborty","userId":"02339058060356792309"}},"outputId":"07dcefb9-fe6e-43ce-b29a-5b557584c891"},"outputs":[{"output_type":"stream","name":"stdout","text":["+---------+---+----------+------+\n","|     Name|age|Experience|Salary|\n","+---------+---+----------+------+\n","|    Krish| 31|        10| 30000|\n","|Sudhanshu| 30|         8| 25000|\n","|    Sunny| 29|         4| 20000|\n","|     Paul| 24|         3| 20000|\n","|   Harsha| 21|         1| 15000|\n","|  Shubham| 23|         2| 18000|\n","+---------+---+----------+------+\n","\n"]}],"source":["# Get the\n","train_df.show()"]},{"cell_type":"code","execution_count":7,"id":"6b3dd5ff","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6b3dd5ff","executionInfo":{"status":"ok","timestamp":1731636855905,"user_tz":-330,"elapsed":556,"user":{"displayName":"Aniket Chakraborty","userId":"02339058060356792309"}},"outputId":"90ce17a5-7f7b-4483-c965-7e7826973198"},"outputs":[{"output_type":"stream","name":"stdout","text":["root\n"," |-- Name: string (nullable = true)\n"," |-- age: integer (nullable = true)\n"," |-- Experience: integer (nullable = true)\n"," |-- Salary: integer (nullable = true)\n","\n"]}],"source":["# Get the schema of the train data set\n","train_df.printSchema()"]},{"cell_type":"code","execution_count":8,"id":"5d3227e6","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5d3227e6","executionInfo":{"status":"ok","timestamp":1731636879011,"user_tz":-330,"elapsed":523,"user":{"displayName":"Aniket Chakraborty","userId":"02339058060356792309"}},"outputId":"73c76261-c105-484d-ea1b-042e60bc8464"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["['Name', 'age', 'Experience', 'Salary']"]},"metadata":{},"execution_count":8}],"source":["# Get the column names of the train_df pyspark data frame\n","train_df.columns"]},{"cell_type":"markdown","source":["#### PySpark's MLlib has some different functionalities than Sklearn's MLlibs\n","- In case of Sklearn, we devide the dataset into **independent and dependent set** using variables X and y\n","- Then we perform **train test split** on that X and y with **80-20** or **70-30** ratio for train and test set preparation\n","- We **build the required ML model** and check its **accuracy**. **Hypertune** in future if required.\n","\n","But in case of PySpark's MLlib construction, we find a way in which we can somehow **group the independent variables**. In other word, we **assemble** the columns that are considered as independent variable.\n","\n","For this notebook, the **'age' and 'Experience'** columns are **independent columns** and **'Salary'** is the **dependent** variable. So, by grouping the **'age'** and **'Experience'** feature, it will **ceate a new feature** that is called as **'IndF'** and it will be given as **[31,10]** for **age 31** and **experience of 10 years**\n","\n","**Task:** The task is to build a simple ML model that can **predict salary** of an individual with the help of his **age** and **experience** in respective field."],"metadata":{"id":"dAj_uzK6nB71"},"id":"dAj_uzK6nB71"},{"cell_type":"code","execution_count":10,"id":"e6273555","metadata":{"id":"e6273555","executionInfo":{"status":"ok","timestamp":1731637824598,"user_tz":-330,"elapsed":514,"user":{"displayName":"Aniket Chakraborty","userId":"02339058060356792309"}}},"outputs":[],"source":["# Importing VectorAssembler to assemble the independent columns for the ML model\n","from pyspark.ml.feature import VectorAssembler\n","features = VectorAssembler(inputCols=[\"age\",\"Experience\"], outputCol= \"IndF\")"]},{"cell_type":"code","execution_count":11,"id":"0b69744c","metadata":{"id":"0b69744c","executionInfo":{"status":"ok","timestamp":1731637829282,"user_tz":-330,"elapsed":504,"user":{"displayName":"Aniket Chakraborty","userId":"02339058060356792309"}}},"outputs":[],"source":["# Use the transform method to create a new pyspark data frame called output\n","# It will create a new feature called\n","output = features.transform(train_df)"]},{"cell_type":"code","execution_count":12,"id":"60961194","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"60961194","executionInfo":{"status":"ok","timestamp":1731637853996,"user_tz":-330,"elapsed":2251,"user":{"displayName":"Aniket Chakraborty","userId":"02339058060356792309"}},"outputId":"42b5a462-984a-4e66-e8c1-f3026f9f213c"},"outputs":[{"output_type":"stream","name":"stdout","text":["+---------+---+----------+------+-----------+\n","|     Name|age|Experience|Salary|       IndF|\n","+---------+---+----------+------+-----------+\n","|    Krish| 31|        10| 30000|[31.0,10.0]|\n","|Sudhanshu| 30|         8| 25000| [30.0,8.0]|\n","|    Sunny| 29|         4| 20000| [29.0,4.0]|\n","|     Paul| 24|         3| 20000| [24.0,3.0]|\n","|   Harsha| 21|         1| 15000| [21.0,1.0]|\n","|  Shubham| 23|         2| 18000| [23.0,2.0]|\n","+---------+---+----------+------+-----------+\n","\n"]}],"source":["# Get the output of the output pyspark data frame object\n","output.show()"]},{"cell_type":"code","execution_count":13,"id":"2c27434a","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2c27434a","executionInfo":{"status":"ok","timestamp":1731637881321,"user_tz":-330,"elapsed":573,"user":{"displayName":"Aniket Chakraborty","userId":"02339058060356792309"}},"outputId":"e8013239-254e-440a-ae79-265130515033"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["['Name', 'age', 'Experience', 'Salary', 'IndF']"]},"metadata":{},"execution_count":13}],"source":["# Get the columns of the output pyspark data frame object\n","output.columns"]},{"cell_type":"code","execution_count":14,"id":"54a0ccab","metadata":{"id":"54a0ccab","executionInfo":{"status":"ok","timestamp":1731637974994,"user_tz":-330,"elapsed":532,"user":{"displayName":"Aniket Chakraborty","userId":"02339058060356792309"}}},"outputs":[],"source":["# Creating the final pysaprk data frame for building the ML object\n","# Store the final data frame as final_df\n","final_df = output.select('IndF', 'Salary')"]},{"cell_type":"code","execution_count":15,"id":"f7a73845","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"f7a73845","executionInfo":{"status":"ok","timestamp":1731638005567,"user_tz":-330,"elapsed":501,"user":{"displayName":"Aniket Chakraborty","userId":"02339058060356792309"}},"outputId":"f2ed6ea9-1d8b-4056-a3fc-8f75f0187842"},"outputs":[{"output_type":"stream","name":"stdout","text":["+-----------+------+\n","|       IndF|Salary|\n","+-----------+------+\n","|[31.0,10.0]| 30000|\n","| [30.0,8.0]| 25000|\n","| [29.0,4.0]| 20000|\n","| [24.0,3.0]| 20000|\n","| [21.0,1.0]| 15000|\n","| [23.0,2.0]| 18000|\n","+-----------+------+\n","\n"]}],"source":["# Check how the final data frame for building the ML object looks like\n","final_df.show()"]},{"cell_type":"markdown","source":["### Future Steps\n","- Once we get the final data for building the ML model (Linear Regression in this case), we divide the data into two parts. The train part and the test part\n","- The train part is build with 75% of the sample, the test part is build with 25% of the sample available.\n","- We define the regressor variable using the LinearRegression object available in the pyspark.ml.regression moduloe\n","- Fit the train data to the model\n","- Get the slope and intercept as coefficients\n","- Predict results with test data\n"],"metadata":{"id":"m515QL6DrBZH"},"id":"m515QL6DrBZH"},{"cell_type":"code","execution_count":16,"id":"0b11192b","metadata":{"id":"0b11192b","executionInfo":{"status":"ok","timestamp":1731638446915,"user_tz":-330,"elapsed":4366,"user":{"displayName":"Aniket Chakraborty","userId":"02339058060356792309"}}},"outputs":[],"source":["# Importing the LinearRegression object for building the model\n","from pyspark.ml.regression import LinearRegression\n","\n","# Train test split the data with 75-25 split as train_data and test_data\n","train_data,test_data=final_df.randomSplit([0.75,0.25])\n","regressor = LinearRegression(featuresCol = 'IndF', labelCol = 'Salary')\n","regressor = regressor.fit(train_data)"]},{"cell_type":"code","execution_count":17,"id":"fa4ec997","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fa4ec997","executionInfo":{"status":"ok","timestamp":1731638483267,"user_tz":-330,"elapsed":579,"user":{"displayName":"Aniket Chakraborty","userId":"02339058060356792309"}},"outputId":"a51b79ca-f861-45d3-ef2d-7ff228799f16"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["DenseVector([109.3058, 1199.4092])"]},"metadata":{},"execution_count":17}],"source":["# Get the Coefficients (slope) of the regressor model using the .coefficients arguement\n","regressor.coefficients"]},{"cell_type":"code","execution_count":18,"id":"eba911b6","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eba911b6","executionInfo":{"status":"ok","timestamp":1731638638756,"user_tz":-330,"elapsed":513,"user":{"displayName":"Aniket Chakraborty","userId":"02339058060356792309"}},"outputId":"1e77a53b-8dce-4224-ec0c-90941ef16e46"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["12187.59231905408"]},"metadata":{},"execution_count":18}],"source":["# Get the intercept of the regressor model\n","regressor.intercept"]},{"cell_type":"code","execution_count":19,"id":"2ba2bc70","metadata":{"id":"2ba2bc70","executionInfo":{"status":"ok","timestamp":1731638693678,"user_tz":-330,"elapsed":503,"user":{"displayName":"Aniket Chakraborty","userId":"02339058060356792309"}}},"outputs":[],"source":["# Predicting the results with the regressor model and by using the test_data; store the result in a variable called pred\n","pred = regressor.evaluate(test_data)"]},{"cell_type":"code","execution_count":20,"id":"489d6392","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"489d6392","executionInfo":{"status":"ok","timestamp":1731638740802,"user_tz":-330,"elapsed":1100,"user":{"displayName":"Aniket Chakraborty","userId":"02339058060356792309"}},"outputId":"803c5176-40ae-4242-9a43-4439da73ede1"},"outputs":[{"output_type":"stream","name":"stdout","text":["+-----------+------+------------------+\n","|       IndF|Salary|        prediction|\n","+-----------+------+------------------+\n","| [24.0,3.0]| 20000|18409.158050221544|\n","|[31.0,10.0]| 30000| 27570.16248153613|\n","+-----------+------+------------------+\n","\n"]}],"source":["# Get the predicted results and show them as a data frame\n","pred.predictions.show()"]},{"cell_type":"code","execution_count":21,"id":"0534e854","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0534e854","executionInfo":{"status":"ok","timestamp":1731638813300,"user_tz":-330,"elapsed":517,"user":{"displayName":"Aniket Chakraborty","userId":"02339058060356792309"}},"outputId":"f28b224e-8ea5-4dd7-8367-8207750d915e"},"outputs":[{"output_type":"stream","name":"stdout","text":["The MAE value will be: 2010.339734121164\n","The MSE value will be: 4217444.237654793\n"]}],"source":["# Get the mean Squared error and Mean Absoute error for the predicted results\n","print('The MAE value will be:', pred.meanAbsoluteError)\n","print('The MSE value will be:', pred.meanSquaredError)"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.10"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}