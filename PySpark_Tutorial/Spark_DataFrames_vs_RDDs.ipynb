{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Br35gPQhweal"
      },
      "outputs": [],
      "source": [
        "# Importing required packages\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import desc"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a SparkSession object as spark with 'DFRDD' app name\n",
        "spark = SparkSession.builder.appName('DFRDD').getOrCreate()"
      ],
      "metadata": {
        "id": "FpFLwsljwrFA"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Word Count example using the 'PySpark_Sample.txt' file\n",
        "- Firstly, the job is done by using an rdd, created as rdd\n",
        "- Secondly, the same job is executed by converting the sample data into data frame format.\n",
        "- In both cases, give the top 10 words having most occurances"
      ],
      "metadata": {
        "id": "bto3XfkIynzK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an RDD form the 'PySpark_Sample.txt' file\n",
        "rdd = spark.sparkContext.textFile('PySpark_Sample.txt')"
      ],
      "metadata": {
        "id": "Ae80L6z_wt8M"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating the result as another rdd named as result_rdd\n",
        "result_rdd = rdd.flatMap(lambda line: line.split(\" \")) \\\n",
        "                .map(lambda word: (word, 1)) \\\n",
        "                .reduceByKey(lambda a, b: a + b) \\\n",
        "                .sortBy(lambda x: x[1], ascending=False)"
      ],
      "metadata": {
        "id": "8GuLq5gdw1jq"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get most 10 frequent words from result_rdd\n",
        "result_rdd.take(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jebMDC7Fw3iA",
        "outputId": "35d49bfb-31a5-4358-90ed-4291f60c37b7"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('the', 34),\n",
              " ('and', 22),\n",
              " ('of', 18),\n",
              " ('a', 16),\n",
              " ('in', 11),\n",
              " ('was', 11),\n",
              " ('with', 11),\n",
              " ('to', 11),\n",
              " ('The', 8),\n",
              " ('that', 8)]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a DataFrame object from 'PySpark_Sample.txt' file\n",
        "df = spark.read.text('PySpark_Sample.txt')"
      ],
      "metadata": {
        "id": "vlNFLvI1xFuz"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Executing the sample word count example using the data frame\n",
        "result_df = df.selectExpr(\"explode(split(value, ' ')) as word\").groupBy(\"word\").count().orderBy(desc(\"count\"))"
      ],
      "metadata": {
        "id": "e_6FOdKixwyu"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the most 10 frequent words from result_df\n",
        "result_df.take(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LpghzDwWyWA9",
        "outputId": "b03b857d-8530-46fa-fb53-733e5536a9cf"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Row(word='the', count=34),\n",
              " Row(word='and', count=22),\n",
              " Row(word='of', count=18),\n",
              " Row(word='a', count=16),\n",
              " Row(word='was', count=11),\n",
              " Row(word='in', count=11),\n",
              " Row(word='with', count=11),\n",
              " Row(word='to', count=11),\n",
              " Row(word='The', count=8),\n",
              " Row(word='that', count=8)]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Stopping the SparkSession\n",
        "spark.stop()"
      ],
      "metadata": {
        "id": "vGqRPxz1yb_F"
      },
      "execution_count": 11,
      "outputs": []
    }
  ]
}